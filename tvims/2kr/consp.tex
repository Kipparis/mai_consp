\documentclass[12pt]{extarticle}


\input{preambule/main.tex}

\DeclareMathOperator*{\argmin}{argmin}   % Jan Hlavacek
\DeclareMathOperator*{\argmax}{argmin}   % Jan Hlavacek

\begin{document}

\tableofcontents
\printindex

% написать закон больших чисел

\section{Теорема о нормальной корреляции}
\subsection{Инфа}
\textit{Наилучшая оценка относительно другого вектора, еще дисперсия
может быть}
\par Есть задачки где требуется просто применить саму формулу (для
условного мат ожидания в теореме о нормальной корреляции). Коварационную
матрицу не дают, а надо какие-то действия проделать
\subsection{Теория}
\subsubsection{Гауссовский вектор}
\begin{eqnarray*}
    f_{X}(x)=(2\pi)^{-\frac{n}{2}}(\textmd{det}\,K_{x})^{-\frac{1}{2}}
    \exp{\left(-\frac {(x-mx)^{T}K_{x}^{-1}(x-mx)} {2}\right)}
\end{eqnarray*}
При индексировании ковариационной матрицы, если мы хотим выбрать
подматрицу $K_{(x_{1},x_{2})x_{3}}$, значит мы должны получить матрицу
\verb|2x1| (2 строчки, 1 столбец). При самой выборке мы из строчек
$x_{1},x_{2}$ берем столбец $x_{3}$

\subsubsection{Квадратичная форма}
\par Если степень квадратичной формы два, то мы смотрим на коэффициенты
при неизвестных второй степени (например $x^{2},y^{2},xy$) и, располагая
их в матрице, получим обратную матрицу ковариации ($K^{-1}$).
\par Чтобы получить мат. ожидание надо найти частные производные и
решить систему уравнений (сколько частных производных, столько и
уравнений)

\subsubsection{Переход к другой переменной}
\begin{eqnarray*}
    Y=AX+b,\ \textmd{а}\ X\sim N(m_{x},K_{x})
    ,\ \textmd{то}\ Y\sim N(Am_{X}+b, AK_{x}A^{T})
\end{eqnarray*}


\subsubsection{С.К.-оптимальная оценка}
Оценка $\hat{X}$ называвется с.к.-оптимальной оценкой для $X$ по
наблюдениям $Y$, если:
\begin{eqnarray*}
    \hat{X}=m_{X}+K_{XY}K_{Y}^{-1}(Y-m_{Y})
\end{eqnarray*}

\subsection{Пример}
\paragraph{Пример 1 (объяснение Горяинова)}
Пусть случайные величины $X$, $Y$ имеют дисперсии $D[X]=\sigma^{2}>0$ и
$D[Y]=9\sigma^{2}$, а коэффициент корреляции $\rho_{XY}$ равен $2/3$.
Обозначим через $\hat{X}$ наилучшую линейную оценку величины $X$ по
величине $Y$. Определить во сколько раз с.к. ошибка этой величины
$\sqrt{M[(\hat{X}-X)^{2}]}$ будет меньше с.к. отклонения величины $X$

\par\textbf{Решение}. \textit{Наилучшая оценка величины $X$ по величине $Y$} - то самое
условное мат. ожидание (про которое в теореме о нормальной корреляции).
Далее, т.к. $\hat{X}$ - тоже гауссовская случайная величина, можем найти
ее мат ожидание и дисперсию, пользуясь той же самой формулой (теорема о
нормальной корреляции). После этого можем найти корень (про который
говорится в условии) и сравнить его с с.к. отклонением величины $X$
($D[X]=\sigma^{2}$)

\par Резюмируя. Находим $\hat{X}$ из теоремы о нормальной корреляции.
Находим его мат. ожидание и дисперсию ($\hat{X}$ тоже нормально
распределенная СВ). И дальше пользуемся этим для того, чтобы решить то,
что нас просят найти.

\paragraph{Пример 2. Переход к новой СВ}
Дано: $z=\left(\begin{array}{c}x\\y \end{array} \right)$. Надо найти
закон распределения $w = x - y$. Тогда
\begin{eqnarray*}
    &&A=(1\ -1)
    ,\ \ b=\left(\begin{array}{c} 0\\0 \end{array} \right)\\
    &&w\sim N(Am_{z}+b,\ AK_{z}A^{T})
\end{eqnarray*}



\section{Сходимости случайных последовательностей}
\subsection{Инфа}
\begin{description}
    \item По определению (С.К., P)
    \item ЗБЧ (последовательность средних арифметических случайных величин
        сходится к мат ожиданию). Можно написать условия выполнения ЗБЧ и
        сказать что сходится
\end{description}
\subsection{Теория}
\subsubsection{С.К. сходимость}
$X_{n} \to X$ \textit{в среднем квадратическом}, если
\begin{eqnarray*}
\lim\limits_{n\rightarrow \infty}M\big[(X_{n}-X)^{2}\big]=0
\end{eqnarray*}
Краткий гайд: выписать мат ожидание квадрата разности и
убедиться что оно сходится к нулю

\subsubsection{Сходимость по вероятности}
$X_{n}\to X$ \textit{по вероятности}, если для любого $\varepsilon > 0$:
\begin{eqnarray*}
    \lim\limits_{n\rightarrow \infty}P(|X_{n}-X|>\varepsilon) = 0
\end{eqnarray*}
Краткий гайд: выписать вероятность и продемострировать что эта
вероятность сходится к нулю при $n \to \infty$. Может приходится
неравенство Чебышева

\subsubsection{ЗБЧ}
$Y_{n}=\frac{1}{n}\sum\limits_{i=1}^{n}X_{i}$
\par\(\left.
    \begin{tabular}{l}
          1. Одинаково распр., нез $X_{1}, \ldots, X_{n}$ \\
          2. $MX_{i}$ - конечно
    \end{tabular}
\right\}\) $Y_{n} \to MX_{1}$ почти наверное (\textit{усиленн. ЗБЧ})

\par \(\left.
    \begin{tabular}{l}
          1. Одинаково распр., нез $X_{1}, \ldots, X_{n}$ \\
          2. $DX_{i} < +\infty$
    \end{tabular}
\right\}\) $Y_{n} \stackrel{P}{\to} MX_{1}$ (\textit{ЗБЧ})

\par \(\left.
    \begin{tabular}{l}
          1. Нез $X_{1}, \ldots, X_{n}$ \\
          2. $DX_{n} \leqslant c$
    \end{tabular}
\right\}\) $|Y_{n}-MY_{n}| \stackrel{P}{\to} 0$ (\textit{ЗБЧ})

\par \(\left.
    \begin{tabular}{l}
          1. Нез $X_{1}, \ldots, X_{n}$ \\
          2. $\lim\limits_{n\rightarrow \infty}DY_{n}=0$
    \end{tabular}
\right\}\) $|Y_{n}-MY_{n}| \stackrel{P}{\to} 0$ (\textit{ЗБЧ})

\subsection{Пример}

\section{Центральная предельная теорема}
\subsection{Инфа}
\begin{description}
    \item Есть много слагаемых, нужно объявить сумму Гауссовской чтобы
        что-то найти
    \item Либо теорема Муавра-Лапласа (биномиальное распределение
        заменяем на нормальное)
\end{description}

\subsection{Теория}
\subsubsection{Приближение Муавра-Лапласа}
\begin{center}
$X \sim Bi(n,p)$
\par\begin{tabular}{c|l}
    Локальное &
    $P(X=k) \approx \frac{1}{\sqrt{2\pi npq}}
    \exp\left(-\frac{(k-np)^{2}}{2npq}\right)$
    \\ \hline
    Глобальное &
    $P(l\leqslant X\leqslant m)
    \approx \Phi_{0}\left(\frac{m-np}{\sqrt{npq}}\right)
    - \Phi_{0}\left(\frac{l-np}{\sqrt{npq}}\right)$
    \\ \hline
    Погрешность &
    $\frac{p^{2}+q^{2}}{\sqrt{npq}}$
\end{tabular}
\end{center}

\subsubsection{Приближение Пуассона}
\begin{center}
$X \sim Bi(n,p)$
\par\begin{tabular}{c|l}
    Локальное &
    $P(X=k)\approx\frac{(np)^{k}e^{-np}}{k!}$
    \\ \hline
    Глобальное &
    $P(l\leqslant X\leqslant m)
    \approx\sum\limits_{k=l}^{m}\frac{(np)^{k}e^{-np}}{k!}$
    \\ \hline
    Погрешность &
    $np^{2}$
\end{tabular}
\end{center}

\subsubsection{Неравенство Чебышева, усиленный вариант}
Пусть $r$-й абсолютный момент СВ $X$ конечен. Тогда выполняется
равенство
\begin{displaymath}
    P(\left|X\right| \geqslant \varepsilon)
    \leqslant M\left[\left|X\right|^{r}\right]/\varepsilon^{r},
    \ \ \varepsilon > 0
\end{displaymath}
\par \textit{Неравенство Чебышева} при $r=2$, $Y=X-m_{X}$
\begin{displaymath}
    P\left\{\left|X-m_{X}\right| \geqslant \varepsilon \right\}
    \leqslant
    \frac{M\left[\left|X-m_{X}\right|^{2}\right]}{\varepsilon^{2}}
    \triangleq \frac{D\left[X\right]}{\varepsilon^{2}}
\end{displaymath}

\subsection{Пример}

\section{Метод максимального правдоподобия, метод моментов}
\subsection{Инфа}
Дана плотность вероятности либо функция распределения. Нужно найти
оценку параметра либо по методу максимального правдоподобия либо по
методу моментов.
\subsection{Теория}
\subsubsection{Метод моментов}
\paragraph{$k$-й начальный момент}\index{Начальный момент} СВ $\xi$:
$\nu^{(k)}[\xi]=M[\xi^{k}]$
\paragraph{$k$-й центральный момент}\index{Центральный момент} СВ $\xi$:
$\mu^{(k)}[\xi]=M[(\xi-M[\xi])^{k}]$
\paragraph{$k$-й выборочный начальный момент}
\index{Выборочный начальный момент} СВ $\xi$:
$\hat{\nu}_{n}^{(k)}=\frac{1}{n}\sum\limits_{i=1}^{n}x_{i}^{k}$
\paragraph{$k$-й выборочный центральный момент}
\index{Выборочный центральный момент}  СВ $\xi$:
$\hat{\mu}_{n}^{(k)}=\frac{1}{n}\sum\limits_{i=1}^{n}(x_{i}-\bar{x})^{k}$
, где $\bar{x}$ - выборочное среднее (среднее арифметическое)

Сам метод моментов: приравниваем теоретические моменты к соответствующим
выборочным и берем столько уравнений, сколько у нас параметров.
\par Например: одна неизвестная: берем 1-й начальный момент (мат
ожидание) и первый выборочный центральный момент (среднее арифетическое)
приравниваем и выражаем $\theta$.
\par Для двух неизвестных получится тоже самое, но прибавится уравнение
со вторым центральным моментом (дисперсией)

\subsubsection{Метод максимального правдоподобия (ММП)}
Есть выборка (знаем закон распределения с точностью до параметра $\theta$)
\begin{eqnarray*}
    &&X_{1},\ldots,X_{n}\sim F(x;\theta)
    ,\ \ \theta\ -\ \textmd{неизв. пар-р}\\
    &&\hat{\theta}-?,\ \ \textmd{оценка}
\end{eqnarray*}

\textit{Функция правдоподобия}\index{Функция правдоподобия}
\begin{eqnarray*}
    L(X_{1},\ldots,X_{n},\theta)=\prod_{i=1}^{n}p(X_{i};\theta)
\end{eqnarray*}
\begin{center} \begin{tabular}{|c|c|}
    Дискретный случай & Непрерывный случай \\\hline
    $p(x,\theta)=P(X_{i}=x)$ & $p(x,\theta)=f_{x_{i}}(x,\theta)$\\\hline
\end{tabular} \end{center}
Тогда оценкой параметра $\theta$ будет
\begin{eqnarray*}
    \hat{\theta}=\argmax_{\theta}L(X_{1},\ldots,X_{n},\theta)
\end{eqnarray*}
Для этого выполняем следующее
\begin{eqnarray*}
    \frac{d\ln L}{d\theta}=0\ \to \hat{\theta}
\end{eqnarray*}
или, если несколько неизвестных
\begin{eqnarray*}
\left\{ \begin{array}{l}
        \frac{\partial\ln L}{\partial\theta_{1}}=0\\
        \ldots\\
        \frac{\partial\ln L}{\partial\theta_{m}}=0
\end{array} \right.\ \ \to \hat{\theta}_{1},\ldots,\hat{\theta}_{m}
\end{eqnarray*}

\subsection{Пример}
\paragraph{Пр.1 ММП}
\begin{eqnarray*}
    X_{1},\ldots,X_{n}\sim Bi(1;p),\ \ \textmd{$\hat{\theta}$ - ?}
\end{eqnarray*}
Решение
\begin{eqnarray*}
    &&p(x;\theta)=\theta^{x}(1-\theta)^{1-x}\\
    &&L(X_{1},\ldots,X_{n},\theta)
    =\prod_{i=1}^{n}\theta^{x_{i}}(1-\theta)^{1-x_{i}}\\
    &&\ln L(X_{1},\ldots,X_{n},\theta)
    =\sum\limits_{i=1}^{n}(x_{1}\ln \theta+(1-x_{i})\ln(1-\theta))\\
    &&\frac{d\ln\,L}{d\theta}
    =\sum\limits_{i=1}^{n}
    \left(x_{i}\frac{1}{\theta}+(1-x_{i})\frac{-1}{1-\theta}\right)\\
\end{eqnarray*}
Упрощаем, получаем
\begin{eqnarray*}
    \sum\limits_{i=1}^{n}x_{i}-n\theta=0\ \Rightarrow
    \ \hat{\theta}=\frac{1}{n}\sum\limits_{i=1}^{n}x_{i}
\end{eqnarray*}

\paragraph{Пр.2 ММП}
\begin{eqnarray*}
    X_{1},\ldots,X_{n}\sim R(0;\theta)
\end{eqnarray*}
Решение
\begin{eqnarray*}
    &&p(x;\theta)=
    \left\{\begin{array}{ll}
            \frac{1}{\theta},&x\in (0;\theta)\\
            0,&x\notin (0;\theta)
    \end{array}\right.\\
    &&L(X_{1},\ldots,X_{n},\theta)=
    \left\{ \begin{array}{ll}
            \left(\frac{1}{\theta}\right)^{n},&\forall i:x_{i}\in
            (0;\theta)\\
            0,&\exists i:x_{i}\notin (0;\theta)
    \end{array}
    \right.
\end{eqnarray*}
Мы не можем найти логарифм и подсчитать производную, поэтому
\textbf{рассуждая} найдем точку максимума без производных. Очевидно что
оно будет не нулем только есть $\theta = X_{(n)}$. Отсюда
\begin{eqnarray*}
    \hat{\theta}=X_{(n)}
\end{eqnarray*}

\paragraph{Пр.3 ММ}
\begin{eqnarray*}
    X_{1},\ldots,X_{n}\sim R(\theta_{1},\theta_{2})
\end{eqnarray*}
Решение
\begin{eqnarray*}
    &&\nu^{(1)}=M[x_{i}]=\frac{\theta_{1}+\theta_{2}}{2}
    ,\ \ \textmd{первый теоретический момент}\\
    &&\mu^{(2)}=D[x_{i}]=\frac{(\theta_{2}-\theta_{1})^{2}}{12}
    ,\ \ \textmd{второй теоретический момент}\\
    &&\hat{\nu}^{(1)}=\bar{X}=\frac{1}{n}X_{i}
    ,\ \ \textmd{первый выборочный момент}\\
    &&\hat{\mu}^{(2)}=S^{2}
    =\frac{1}{n}\sum\limits_{i=1}^{n}(x_{1}-\bar{x})^{2}
    ,\ \ \textmd{второй выборочный момент}
\end{eqnarray*}
\textit{Теоретические моменты находим из законов распределения.
    Выборочные находим из определений выборочных моментов.}
Приравнивая соответствующие моменты получим систему уравнений:
\begin{eqnarray*}
    \left\{ \begin{array}{l}
            \nu^{(1)}=\hat{\nu}^{(1)}\\
            \mu^{2}=\hat{\mu}^{2}
    \end{array}
    \right.
\end{eqnarray*}
Подставляем, ($\bar{x},\ S^{2}$ считаются известными, т.к. мы их узнаем
при проведении измерений). Получаем оценки
\begin{eqnarray*}
&&\theta_{1}=\bar{x}\pm\sqrt{3}S\\
&&\theta_{2}=\bar{x}\pm\sqrt{3}S
\end{eqnarray*}
Т.к. по распределению очевидно что $\theta_{1}<\theta_{2}$, то:
\begin{eqnarray*}
    &&\hat{\theta_{1}}=\bar{x}-\sqrt{3}S\\
    &&\hat{\theta_{1}}=\bar{x}+\sqrt{3}S
\end{eqnarray*}


\section{Доверительные интервалы}
\subsection{Инфа}
\begin{description}
    \item Для мат ожидания при неизвестной дисперсии
    \item Для дисперсии при неизвестном мат ожидании
\end{description}

\subsection*{Теория}
\paragraph{Интервальной оценкой}\index{Интервальная оценка}
(доверительным интервалом \index{Доверительный интервал}) надежности
$1-\alpha$ для параметра $\theta$ называется интервал с зависящими от выборки
случайными концами:
\begin{eqnarray*}
    P\Big(T_{1}\big(X_{1},\ldots,X_{n}\big)<\theta <
    T_{2}\big(X_{1},\ldots,X_{n}\big)\Big)=1-\alpha
\end{eqnarray*}
обычно еще $\alpha$ - \textit{уровень значимости}\index{Уровень
    значимости}, $1-\alpha$ - \textit{уровень доверия}(\textit{уровень
    надежности}) \index{Уровень надежности}\index{Уровень
доверия} По умолчанию берем уровень значимости равным $0.05$
($\alpha=0.05$)

\paragraph{Мат. ожидание неизвестно, дисперсия известна}

\[X_{1},\ldots,X_{n}\sim N(\theta;\sigma^{2})\]
$\theta$ - неизв., $\sigma$ - извест. В таком случае, интервальной
оценкой является
\begin{eqnarray*}
    P(
    \bar{X}-u_{1-\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}}
    < \theta <
    \bar{X}+u_{1-\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}})
\end{eqnarray*}
где $\bar{X}$ - выборочное среднее,
$u_{\frac{\alpha}{2}},u_{1-\frac{\alpha}{2}}$ - квантили
распределения $N(0;1)$

\paragraph{Дисперсия неизвестна, мат. ожидание известно}
$X\sim N(m;\theta)$, $m$ - неизвестно, $\theta$ известно
\begin{eqnarray*}
    P\left(
    \frac{\sum\limits_{i=1}^{n}(X_{i}-m)^{2}}{k_{1-\frac{1}{2},\,n}}
    \leqslant\theta\leqslant
    \frac{\sum\limits_{i=1}^{n}(X_{i}-m)^{2}}{k_{\frac{1}{2},\,n}}
    \right)=1-\alpha
\end{eqnarray*}
где $k_{n,\,\alpha}$ - квантиль распределения $\chi^{2}$ (хи-квадрат),
с $n$ степенями свободы, уровня $\alpha$



\subsection{Примеры}
\paragraph{Пример 1. Дисперсия известна, мат. ожидание неизвестно}
$X\sim N(\theta, 10^{2})$, $\theta$ - неизвестная. Выборка
\begin{eqnarray*}
X = (31,90,16,80,28,61,66,60,15,88,41,79,97)
\end{eqnarray*}
В формулу для интервальной оценки
\begin{eqnarray*}
    P(
    \bar{X}-u_{1-\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}}
    < \theta <
    \bar{X}+u_{1-\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}})
\end{eqnarray*}
подставляем значения: $\sigma=10$, $n=13$, $\alpha=0.05$,
$u_{0.975}=1.96$, $\bar{X}=57.85$ (среднее арифм. по выборке). Получаем
оценку:
\begin{eqnarray*}
     57.85-\frac{1.96\cdot 10}{\sqrt{13}}
    &\leqslant\theta\leqslant&
    57.85+\frac{1.96\cdot 10}{\sqrt{13}}\\
    52.41& \leqslant \theta \leqslant & 63.29
\end{eqnarray*}



\section{Проверка гипотез}

\subsection{Инфа}
Следующие типы гипотез:
\begin{description}
    \item Про вероятность успеха (пример про водителей
        виновников ДТП)
    \item О равенстве долей/вероятностей успеха в двух сериях
        опытов
    \item О равенстве средних (задача о сдвиге)
        \subitem критерий Вилкексона, критерий Стьюдента
    \item Независимость двух номинальных признаков
        \subitem критерий хи-квадрат Пирсона
    \item Независимость двух порядковых признаков
        \subitem критерий Спирмена (если количественные - ренжируем)
\end{description}
\textit{На параметрические гипотезы задачек не будет (только если где
вероятность успеха)}

\subsection{Теория}
\paragraph{Классификация гипотез}
\begin{center}
    \begin{tabular}{l|c|c}
                          & простые & сложные\\\hline
        параметрические   & $p=2$ & $p>2\ \textmd{или}\ p\neq 2 $\\\hline
        непараметрические & $X\sim N(0;16)$ & $X\sim N(m;d)$\\
                          & $X$ и $Y$ независимы & $X$ и $Y$ зависимы
\end{tabular}
\end{center}

\subsubsection{Гипотеза о вероятности успеха в схеме Бернулли}
Проведена серия из $n$ опытов по схеме Бернулли. Известны результаты
всех опытов: $X_{i}=1$, если $i$-й опыт был успешным, $X_{i}=0$, если
неудачным. $p$ - неизвестная нам вероятность успеха.
\par Нужно проверить гипотезу $H_{O}:p=p_{0}$ против одной из
альтернатив $H_{A}: p > p_{0}$ либо $H_{A}:p<p_{0}$ либо $H_{A}:p\neq
p_{0}$
\par Статистика критерия
\begin{eqnarray*}
    T^{*} = \frac{T-np_{0}}{\sqrt{np_{0}(1-p_{0})}}
    =\frac{\sum\limits_{i=1}^{n}X_{i}-np_{0}}{\sqrt{np_{0}(1-p_{0})}}
\end{eqnarray*}
где $T=X_{1}+\ldots+X_{n}$ - общее число успехов. Если гипотеза $H_{0}$
верна, то $T^{*}\sim N(0;1)$.
\par В конце обязательно сказать одно из:
\begin{description}
    \item Основная гипотеза принимается при уровне значимости $\ldots$
        (значение $\alpha$)
    \item Основная гипотеза отвергается в пользу альтернативной при
        уровне значимости $\ldots$ (значение $\alpha$)
\end{description}

\subsubsection{О равенстве долей успеха в двух сериях опытов}
Проведено две серии опытов по схеме Бернулли. Вероятности "успеха"
равны:
\begin{description}
    \item В первой серии опытов: $p_{1}$
    \item Во второй серии опытов: $p_{2}$
\end{description}
Обе эти вероятности неизвестны. Результаты эксперимента выглядят так:
\begin{center}\begin{tabular}{l|c|c|c}
             & успехи & неудачи & всего \\
    I серия  & $n_{11}$ & $n_{12}$ & $n_{1\cdot}$\\\hline
    II серия & $n_{21}$ & $n_{22}$ & $n_{2\cdot}$\\\hline
    всего    & $n_{\cdot 1}$ & $n_{\cdot 2}$ & $n$
\end{tabular}
\end{center}
Нужно проверить гипотезу: $H_{O}: p_{1}=p_{2}=p$, против одной из
альтернатив $H_{A}:p_{1}>p_{2}$ либо $H_{A}:p_{1}<p_{2}$ либо
$H_{A}:p_{1}\neq p_{2}$

\par\textbf{Статистика критерия}
\begin{eqnarray*}
T=\frac
{\frac{n_{11}}{n_{1\cdot}}-\frac{n_{12}}{n_{2\cdot}}}
{\sqrt{\frac{n_{\cdot 1}}{n}
        (1-\frac{n_{\cdot 1}}{n})
    (\frac{1}{n_{1\cdot}}+\frac{1}{n_{2\cdot}})
}}
\end{eqnarray*}
Если гипотеза $H_{O}$ верна, то $T\sim N(0;1)$.
\begin{center} \begin{tabular}{c|c|c}
    $H_{A}$ & Критическая область & P-значение \\\hline
    $p_{1}\neq p_{2}$ & по обе стороны &
    $P=\min\left\{2\Phi(T);2-2\Phi(T)\right\}$\\\hline
    $p_{1}>p_{2}$ & справа & $P=1-\Phi(T)$ \\\hline
    $p_{1}<p_{2}$ & слева & $P=\Phi(T)$ \\
\end{tabular} \end{center}


\subsubsection{О равенстве средних (задача о сдвиге)}
Есть две выборки $X_{1},\ldots,X_{m}$ и $Y_{1},\ldots,Y_{n}$. Нужно
понять, является ли значимым различие средних значений этих выборок.
\par Предполагается, что:
\begin{description}
    \item $X_{1},\ldots,X_{m}\sim F(x)$
    \item $Y_{1},\ldots,Y_{n}\sim F(x+\theta)$
\end{description}
$\theta$ - насколько измеряемый показатель для второй выборки больше,
чем для первой (то, что нас интересует)
\par\textbf{Формулировка гипотезы} Нужно проверить гипотезу
$H_{O}:\theta=0$ против одной из альтернатив: $H_{A}:\theta >(<,\neq)\,0$

\paragraph{Критерий Вилкоксона (Манна-Уитни)}
Элементы  объединённой выборки из $X_{i}$ и $Y_{j}$ упорядочиваются по
возрастанию и нумеруются. Эта процедруа называется ранжированием, а
получающиеся номера - рангами.
\par $R_{i}$ - ранг $Y_{i}$ в объединенной выборке
\begin{eqnarray*}
    \widetilde{W}=\frac{W-M[W]}{\sqrt{D[W]}}
\end{eqnarray*}
где $W=\sum\limits_{i=1}^{n}R_{i}$, $M[W] = \frac{n}{2}(m+n+1)$,
$D[W]=\frac{mn}{12}(m+n+1)$. Если гипотеза $H_{O}$ верна, то
$\widetilde{W}\sim N(0;1)$
\begin{center} \begin{tabular}{c|c|c}
    $H_{A}$ & Критическая область & P-значение \\\hline
    $\theta\neq 0$ & по обе стороны &
    $P=\min\left\{2\Phi(T);2-2\Phi(T)\right\}$\\\hline
    $\theta > 0$ & справа & $P=1-\Phi(T)$ \\\hline
    $\theta < 0$ & слева & $P=\Phi(T)$ \\
\end{tabular} \end{center}

\subsubsection{Независимость двух номинальных признаков}
% 7 или 8 лекция
\paragraph{Таблица сопряженности.}\index{Таблица сопряженности}
$A$ и $B$ - номинальне признаки. $A$ имеет $k$ градаций, $B$ - $m$
градаций
\begin{center}\begin{tabular}{c|c|c|c|c|c}
            & $A_{1}$ & $A_{2}$ & $\ldots$ & $A_{k}$ & всего \\\hline
    $B_{1}$ & $n_{11}$ & $n_{12}$ & $\ldots$ & $n_{1k}$ & $n_{1\cdot}$\\\hline
    $B_{2}$ & $n_{21}$ & $n_{22}$ & $\ldots$ & $n_{2k}$ & $n_{2\cdot}$\\\hline
    \vdots  & \vdots &\vdots & $\ddots$ &\vdots & \vdots\\\hline
    $B_{m}$ & $n_{m1}$ & $n_{m2}$ & $\ldots$ & $n_{mk}$ & $n_{m\cdot}$\\\hline
    всего & $n_{\cdot 1}$ & $n_{\cdot 2}$ & \ldots & $n_{\cdot k}$ & $n$
\end{tabular}
\end{center}
$n_{ij}$ - количество объектов, относящихся к градациям $A_{i}$ и $B_{j}$

\par\textbf{Гипотезы.}:
\begin{description}
    \item $H_{O}$: для всех $i,j$ $P(A_{i}B_{j})=P(A_{i})P(B_{j})$
        (\textit{признаки независимы})
    \item $H_{A}$: найдутся
        $i^{*},j^{*}:\,P(A_{i^{*}}B_{j^{*}})\neq
        P(A_{i^{*}})P(B_{j^{*}})$
\end{description}

\paragraph{Критерий хи-квадрат Фишера-Пирсона}
\begin{eqnarray*}
    \hat{\chi}^{2}
    =\sum\limits_{i=1}^{m}\sum\limits_{j=1}^{k}
    \frac{\left(n_{ij}-\frac{n_{i\cdot}n_{\cdot j}}{n}\right)^{2}}
    {\frac{n_{i\cdot}n_{\cdot j}}{n}}
\end{eqnarray*}
Если гипотеза $H_{0}$ верна, то
$\hat{\chi}^{2}=\chi^{2}\big((k-1)(m-1)\big)$
\par Критическая область будет справа, т.е. надо оритентироваться на
значение $\chi^{2}_{(k-1)(m-1);\;1-\alpha}$

\subsubsection{Независимость двух порядковых признаков}
Есть результаты наблюдения двух признаков $X$ и $Y$ для каждого из $n$
объектов
\begin{description}
    \item $r_{i}$ - место $i$-го объекта при упорядочивании по признаку
        $X$
    \item $s_{i}$ - место $i$-го объекта при упорядочивании по признаку
        $Y$
\end{description}
Гипотезы:
\begin{description}
    \item $H_{O}$: признаки $X$ и $Y$ независимы (информация об одном
        ничего не говорит о втором)
    \item $H_{A}$: между $X$ и $Y$ монотонная зависимость
\end{description}
\paragraph{Критерий Спирмена (Spearman)}
\begin{eqnarray*}
    &&S=\sum\limits_{i=1}^{n}(r_{i}-s_{i})^{2}\\
    &&\hat{\rho}_{S}=1-\frac{6S}{n^{3}-n}
    ,\ \ \textmd{ранговый коэффициент корреляции Спирмена}\\
    && -1\leqslant \hat{\rho}_{S} \leqslant 1 \\
    && \hat{\rho}_{S}=0\ -\ \ \textmd{монотонной зависимости нет}
\end{eqnarray*}
\par Статистика критерия Спирмена \index{Статистика критерия Спирмена}
\begin{eqnarray*}
    T=\sqrt{n-1}\hat{\rho}_{S}
\end{eqnarray*}
Если $H_{o}$ верна, то $T\sim N(0;1)$, $P=\min\{2\Phi(T);2-2\Phi(T)\}$,
критические области с двух сторон.

\paragraph{Критерий Кендалла (Kendall)}
Будем называть $i$-й и $j$-й объекты согласованной парой, если
\begin{description}
    \item либо $r_{i}<r_{j}$ и $s_{i}<s_{j}$
    \item либо $r_{i}>r_{j}$ и $s_{i}>s_{j}$
\end{description}
$K$ - число несогласованных пар. Как быстро считать: отсортировываем по
первой строчке, идем по нижней строчке и смотрим сколько справа стоит
чисел меньше чем оно само, складываем каждое такое число и получаем $K$.
\begin{eqnarray*}
\hat{\tau}=1-\frac{4K}{n(n-1)}
\ \ \parbox{15em}{Коэффициент согласованности (коэффициент конкордации,
коэффициент Кендалла)}
\end{eqnarray*}
\begin{eqnarray*}
    & -1\leqslant \hat{\tau}\leqslant 1\\
    & \hat{\tau}=0 & -\ \ \textmd{нет зависимости}\\
    & \hat{\tau}=1 & -\ \ \textmd{прямая зависимость}\\
    & \hat{\tau}=-1 & -\ \ \textmd{обратная зависимость}
\end{eqnarray*}
Статистика критерия Кендалла \index{Статистика критерия Кендалла}
\begin{eqnarray*}
    T=\frac{3\sqrt{n}}{2}\hat{\tau}
\end{eqnarray*}
Если $H_{o}$ верна, то $T\sim N(0;1)$, $P=\min\{2\Phi(T);2-2\Phi(T)\}$,
критические области с двух сторон.


\subsection{Примеры}
\paragraph{Пример 1. Про вероятность успеха}
Из 637 спровоцированных водителями ДТП, зарегистрированных отделением
ГИБДД за 3 месяца, 183 произошли по вине водителей-женщин.
Свидетельствуют ли эти данные о том, что женщиты водят аккуратнее
мужчин, если доля женщин среди водителей равна \verb|30%|
\par \textbf{Формулируем гипотезу:} вероятность успеха в схеме бернулли $<
\frac{3}{10}$ (вероятность того, что наугад выбранный виновник ДТП
окажется женщиной). Т.к. эта гипотеза \textit{сложная}, то она будет
альтернативной. Основной гипотезой будет то, что вероятность успеха $=
\frac{3}{10}$
\begin{eqnarray*}
&&H_{O}:p=0,3\\
&&H_{A}:p<0,3\\
\end{eqnarray*}
\par \textbf{Формулируем утверждение:} Если гипотеза $H_{O}$ верна, то
$T^{*}\sim N(0;1)$
\par \textbf{Вычисляем значениеи статистики критерия:}
\begin{eqnarray*}
    T^{*}=\frac{183-637\cdot 0,3}{\sqrt{637\cdot 0,3(1-0,3)}}=-1,20
\end{eqnarray*}
\par \textbf{Строим доверительную и критическую области}: т.к.
альтернативная гипотеза говорит о том, что вероятность должна быть
меньше указанной, то критическая область будет слева и мы считаем
квантиль $u_{\alpha}$ ($u_{0,05}=-1,65$). Отмечаем на линии полученную
статистику
\par \textbf{Принимаем решение:} $H_{O}$ принимается на уровне
значимости \verb|0,05| (т.е. $T^{*}$ находится в доверительной области)

\paragraph{Пример 2. О равенстве долей в двух сериях опытов}
Проводилось \verb|A/B| тестирование интерфейса интернет-магазина.
Конверсия в покупку у варианта \verb|A| - \verb|4,2%| при выборке в
\verb|1100| пользователей, у варианта \verb|B| - \verb|3%| при выборке в
\verb|1000| пользователей. Определите, является ли преимущество варианта
\verb|A| значимым.

\par\textbf{Математическая модель}
\begin{description}
    \item $p_{1}$ - вероятность покупки при варианте \verb|A|
    \item $p_{2}$ - вероятность покупки при варианте \verb|B|
\end{description}
\begin{center}\begin{tabular}{l|c|c|c}
& купил & не купил & всего \\\hline
    \verb|A| & \verb|46| & \verb|1054| & \verb|1100| \\\hline
    \verb|B| & \verb|30| & \verb|970| & \verb|1000| \\\hline
    всего & \verb|76| & \verb|2024| & \verb|2100|
\end{tabular} \end{center}

\par\textbf{Гипотезы:}
\begin{description}
    \item $H_{O}: p_{1}=p_{2}$
    \item $H_{A}: p_{1}>p_{2}$
\end{description}

\par\textbf{Утверждение о статистике критерия:} Если гипотеза $H_{O}$
верна, то $T\sim N(0;1)$

\par\textbf{Вычисляем значение статистики критерия:} $T=1,46$
(подставляем значения в формулу из теории)

\par\textbf{Строим доверительную и критическую области:} Т.к.
критическая область справа и квантиль для нее равен $u_{1-\alpha}=1,65$,
то значение $T=1,46$ попадает в доверительную область. 

\par \textbf{Принимаем решение:} Статистика критерия попала в
доверительную область, следовательно гипотеза $H_{O}$ принимается.

\par\textbf{Вычисляем P-значение}
\begin{eqnarray*}
    u_{1-P}=1,46
    ,\ \ P=1-\Phi(1,46)=1-0,9279=0,0721
\end{eqnarray*}

\paragraph{Пример 3. О равенстве средних}
Проводилось \verb|A/B| тестирование страницы онлайн-табло аэропорта.
Договорились, что лучшим будет считаться вариант, при котором человек
быстрее находит нужный рейс и проводит на странице меньше времени. 10
человек попали на вариант \verb|A| провели на странице: \verb|30|,
\verb|28|, \verb|46|, \verb|42|, \verb|35|, \verb|33|, \verb|44|,
\verb|43|, \verb|31|, \verb|38| секунд. 8 человек, которые попали на
вариант \verb|B| провели на странице: \verb|26|, \verb|38|, \verb|39|,
\verb|28|, \verb|30|, \verb|27|, \verb|32|, \verb|35| секунд. Можно ли
считать что вариант \verb|B| значимо лучше варианта \verb|A|?

\par\textbf{Математическая модель}
\begin{description}
    \item $X_{1},\ldots,X_{m}\sim F(x)$ - время у пользователей с
        интерфейсом \verb|A|
    \item $Y_{1},\ldots,Y_{n}\sim F(x+\theta)$ - время у пользователей с
        интерфейсом \verb|B|
\end{description}

\par\textbf{Гипотезы}
\begin{description}
    \item $H_{O}:\theta=0$
    \item $H_{A}:\theta<0$
\end{description}

\par\textbf{Утверждение о статистике критерия.} Если гипотеза $H_{O}$
верна, то $\widetilde{W}\sim N(0;1)$

\par\textbf{Вычисляем значение статистики критерия.} $W=57,5$,
$M[W]=76$, $D[W]=126,67$
\begin{eqnarray*}
    \widetilde{W}=-1,69
\end{eqnarray*}

\par\textbf{Строим доверительную и критическую области.} Критическая
область будет слева (т.к. $H_{A}:\theta < 0$)

\par\textbf{Принимает решение.} Статистика критерия попала в критическую
область ($u_{0.05}>\widetilde{W}$, $-1.65>-1.69$). Следовательно
гипотеза $H_{O}$ отвергается в пользу $H_{A}$

\par\textbf{Вычисляем P-значение}.
\begin{eqnarray*}
    u_{P}=-1.69
    \ \ P=\Phi(-1.69)=0.0455
\end{eqnarray*}

\paragraph{Пример 4. Независимость двух номинальных признаков}
Есть предположение о том, что род занятий человек связан с желанием
продвиуться по службе. Чтобы выяснить, справедливо ли оно, было
проведено исследование и получены следующие результаты
\begin{center}\begin{tabular}{l|c|c|c}
    & Хотят & Не хотят & \\
    & продвинуться & продвинуться & \\\hline
    Офисные работники & 47 & 7 & 54 \\\hline
    Квалифицированные рабочие & 49 & 30 & 79 \\\hline
    Неквалифицированные рабочие & 65 & 85 & 150 \\\hline
                                & 161 & 122 & 283
\end{tabular}
\end{center}

\par\textbf{Гипотезы}:
\begin{description}
    \item $H_{O}$: для всех $i,j$ $P(A_{i}B_{j})=P(A_{i})P(B_{j})$
        (\textit{признаки независимы})
    \item $H_{A}$: найдутся
        $i^{*},j^{*}:\,P(A_{i^{*}}B_{j^{*}})\neq
        P(A_{i^{*}})P(B_{j^{*}})$
\end{description}

\par\textbf{Утверждение о статистике критерия.} Если гипотеза $H_{O}$
верна, то $\hat{\chi}^{2}\sim\chi^{2}\Big((k-1)(m-1)\Big)$

\par\textbf{Вычисляем значение статистики критерия.}
\begin{eqnarray*}
    \hat{\chi}^{2}
    =\sum\limits_{i=1}^{m}\sum\limits_{j=1}^{k}
    \frac{\left(n_{ij}-\frac{n_{i\cdot}n_{\cdot j}}{n}\right)^{2}}
    {\frac{n_{i\cdot}n_{\cdot j}}{n}}
    =7.873
\end{eqnarray*}

\par\textbf{Строим доверительную и критическую области.} Критическая
область будет всегда справа. $\chi^{2}_{2;\,0.95}=5.991$,
$\hat{\chi}^{2}=7.873$ ($\alpha=0.05$)

\par\textbf{Принимаем решение.} Статистика критерия попала в критическую
область, следовательно гипотеза $H_{O}$ отвергается в пользу $H_{A}$

\par\textbf{Вычисляем P-значение}.
\begin{eqnarray*}
    \chi^{2}_{2;\ 1-P}=7.783
    \ \ 1-P\approx 0.98
    \ \ P\approx 1-0.98=0.02
\end{eqnarray*}

\paragraph{Пример 5. Независимость двух порядковых признаков}
Бегуны, места которых при построении по росту были 1,2,$\ldots$,11,
показали в забеге на 100 метров следующие результаты (в секундах):
10.7, 10.4, 10.2, 10.3, 10.1, 11.0, 10.6, 10.8, 10.9, 10.5, 11.3.
Существует ли зависимость между ростом бегуна и скоростью бега?

\par\textbf{Строим математическую модель.} Выписываем 2 строчки (рост и
время в забеге), снизу, под временем, пишем ранг при ранжировании по
времени
\par\textbf{Формулируем гипотезы.}
\begin{description}
    \item $H_{O}$: независимы
    \item $H_{A}$: монотонная зависимость
\end{description}
\par \textbf{Критерий Спирмена}.
\begin{eqnarray*}
    &&S=100\\
    &&\hat{\rho}_{S}=1-\frac{6S}{n^{3}-n}\approx 0.55\\
    &&T=\sqrt{11-1}\cdot 0.55\approx 1.74
\end{eqnarray*}
\par\textbf{Утверждение о статистике критерия.} Если $H_{O}$ верна, то
$T\sim N(0;1)$
\par\textbf{Строим критические области.} $u_{0.025}=-1.96$,
$u_{0.975}=1.96$.
\par\textbf{Принимаем решение.} $T$ попадает в доверительную область,
значит мы принимает основную гипотезу на уровне доверия $\alpha=0.05$

\par\textbf{Критерий Кендалла.}
\begin{eqnarray*}
&&K=16\\
&&\hat{\tau}=1-\frac{4K}{n(n-1)} = 1-\frac{4\cdot
18}{11(11-1)}\approx 0.35\\
&&T = \frac{3\sqrt{11}}{2}\cdot 0.35 = 1.74
\end{eqnarray*}
Далее повторяем ту же последовательность вывода, что и выше (утверждение
о статистике критерия, построение критических областей, принятие решения)



\section{Метод наименьших квадратов}
\subsection{Инфа}
С помощью метода наименьших квадратов построить прямую/параболлу по пяти
точкам. Дают иксы, игрики, функциональную зависимость, надо найти
параметры. Т.е. дана табличка в которой 4-5 точек и сказано
\begin{eqnarray*}
Y=-aX + b
\end{eqnarray*}
\textit{параметра всегда два}. Надо найти оценки $a$ и $b$ с помощью
метода наименьших квадратов (можно матрицей).

\subsection{Теория}
Задача: оценить неизвестные параметры $\theta_{j}$, т.е. подобрать такие
значения, при которых график $f\big(X\big)$ проходит близко к точкам.
\par Расстояние от линии до точек
\begin{eqnarray*}
    R=\sum\limits_{i=1}^{n}\rho\Big(Y_{i}-f\big(X_{i}\big)\Big)
\end{eqnarray*}
где $\rho$ - которая функция. Получаем что (оценка при которой расстояние до
точек наименьшее)
\begin{eqnarray*}
    \hat{\theta}=\argmin_{\theta}R(\theta_{1},\ldots,\theta_{m})
\end{eqnarray*}
Для метода наименьших квадратов:
\begin{eqnarray*}
    \rho(u)=u^{2}
\end{eqnarray*}
Чтобы найти оценки, переписываем в матричном виде задание:
\begin{eqnarray*}
H=
\left( \begin{array}{cccc}
        h_{1}(X_{1}) & h_{2}(X_{1})&\ldots&h_{m}(X_{1})\\
        h_{1}(X_{2}) & h_{2}(X_{2})&\ldots&h_{m}(X_{2})\\
        \vdots       & \vdots& &\vdots \\
        h_{1}(X_{n}) & h_{2}(X_{n})&\ldots&h_{m}(X_{n})\\
\end{array} \right)
\ \ Y=
\left( \begin{array}{c}
        Y_{1}\\Y_{2}\\\vdots\\Y_{n}
\end{array} \right)
\ \ \hat{\theta}=
\left( \begin{array}{c}
        \hat{\theta}_{1}\\
        \hat{\theta}_{2}\\
        \vdots\\
        \hat{\theta}_{m}
\end{array} \right)
\end{eqnarray*}
В матрице $H$ будет столько столбцов, какой степени многочлен ты взял
\begin{eqnarray*}
\hat{\theta}=(H^{T}H)^{-1}H^{T}Y
\end{eqnarray*}

\subsection{Примеры}
\paragraph{Пример 1.}
По наблюдениям $y_{k}=at_{k}+b+\varepsilon_{k}$ $k=1,\ldots,7$,
$\varepsilon_{1},\ldots,\varepsilon_{7}$ - независимые, одинаково
распределенные СВ по закону $N(0;\sigma^{2})$ (помехи). Оценить $a,\,b$
в модели $y=at+b$ используя МНК
\begin{eqnarray*}
    &&Y=\left(\begin{array}{c}
            5064\\5065.2\\5166\\5193.6\\5310.4\\5278\\5115
    \end{array} \right)
    \ \ H=\left(\begin{array}{cc}
            t_{1}&1 \\ t_{2} & 1\\ t_{3} & 1\\ t_{4} & 1 \\ t_{5} & 1\\
            t_{6} & 1 \\t_{7} & 1
    \end{array} \right)\\
    &&Y=H\theta + W
    \ \ \theta=\left(\begin{array}{c}a\\b \end{array}\right)
    \ \ W=\left(\begin{array}{c}
            \varepsilon_{1}\\\varepsilon_{2}\\\vdots\\\varepsilon_{7}
    \end{array} \right)\\
    &&\theta^{*}=(H^{T}H)^{-1}A^{T}Y
\end{eqnarray*}


\section{Разная теория}
\paragraph{Нормальное распределение}
\begin{eqnarray*}
    &&w\sim N\left(\frac{5}{4}, \frac{3}{8}\right)\\
    &&P(w\leqslant
    0)=F_{w}(0)=\Phi\left(\frac{0-\frac{5}{4}}{\sqrt{\frac{3}{8}}}\right)
    =\frac{1}{2}+\Phi_{0}\left(\frac{0-\frac{5}{4}}{\sqrt{\frac{3}{8}}}\right)
\end{eqnarray*}

\paragraph{Ковариация.}\index{Ковариация}
\begin{eqnarray*}
    &&\textmd{cov}(x,y)=M[xy]-MxMy\\
    &&\textmd{cov}(x,x)=Dx
\end{eqnarray*}
Если $x,y$ независимые СВ, то
\begin{eqnarray*}
    \textmd{cov}(x,y)=0
\end{eqnarray*}

\paragraph{Подсчет квантилей}
Вычитаем из значения $\frac{1}{2}$ и ищем в таблице ту точку, в которой
находится полученное значение.
\begin{center}
Квантили стандартного нормального распределения $u\sim N(0;1)$
\par\begin{tabular}{c | c}
    $\alpha$ & $u_{\alpha}$ \\\hline
    $0.975$ & $1.96$\\
    $0.95$ & $1.645$ \\
    $0.05$ & $1.645$ \\
    $0.025$ & $1.96$
\end{tabular}
\end{center}

\paragraph{Выборочная функция распределения}
\index{Выборочная функция распределения}
- оценка точной функции
распределения
\begin{eqnarray*}
    \hat{F}_{n}(x)=
    \left\{\begin{array}{ll}
            0,&x < X_{(1)},\\
            \frac{k}{n},&X_{(k)}\leqslant x < X_{(k+1)},\\
            1,& x \geqslant X_{(n)}.
    \end{array}\right.
\end{eqnarray*}

\paragraph{Распределение хи-квадрат}\index{Распределение хи-квадрат}
\begin{eqnarray*}
    &&\xi_{1},\xi_{2},\ldots,\xi_{n}\sim N(0;1)\ -\ \textmd{незав}\\
    &&\eta=\sum\limits_{i=1}^{n}\xi_{i}^{2}
\end{eqnarray*}
Закон распределения $\eta$ называется распределением хи-квадрат с $n$
степенями свободы: $\eta\sim\chi^{2}(n)$
\par $k_{12,\,0.05=5.2260}$

\paragraph{Распределение Стьюдента}\index{Распределение Стьюдента}
\begin{eqnarray*}
    &&\xi_{0},\xi_{1},\ldots,\xi_{n}\sim N(0;1)\ -\ \textmd{незав}\\
    &&\zeta=\frac{\xi_{0}}{\sqrt{\frac{1}{n}\sum\limits_{i=1}^{n}\xi_{i}^{2}}}
\end{eqnarray*}
Закон распределения $\zeta$ называется распределением Стьюдента с $n$
степенями свободы: $\zeta \sim t(n)$. $t_{0.95,\,4}=2.132$

\paragraph{Исследование зависимости двух количественных признаков}
Гипотезы:
\paragraph{1. Признаки имеют нормальное распределение}
\begin{description}
    \item $H_{O}$: $r_{XY}=0$ (признаки $X$ и $Y$ некоррелированны, т.е.
        независимы)
    \item $H_{A}$: $r_{XY}\neq 0$ (признаки $X$ и $Y$ коррелированны, т.е.
        зависимы)
\end{description}
Выборочный коэффициент корреляции\index{Выборочный коэффициент
корреляции}:
\begin{eqnarray*}
    &&\hat{r}_{XY}
    =\frac{\frac{1}{n}\sum\limits_{i=1}^{n}(X_{i}-\bar{X})(Y_{i}-\bar{Y})}
    {\sqrt{\frac{1}{n}\sum\limits_{i=1}^{n}(X_{i}-\bar{X})
    \cdot \frac{1}{n}\sum\limits_{i=1}^{n}(Y_{i}-\bar{Y})}}\\
    && -1\leqslant \hat{r}_{XY} \leqslant 1
\end{eqnarray*}
Статистика критерия:
\begin{eqnarray*}
    T=\sqrt{n}\hat{r}_{XY}
\end{eqnarray*}
Если $H_{o}$ верна, то $T\sim N(0;1)$, $P=\min\{2\Phi(T);2-2\Phi(T)\}$,
критические области с двух сторон.

\paragraph{2. Распределение не нормальное, подозревается монотонная
зависимость}

Переходим к порядковой шкале, применяем критерий Спирмена или критерий
Кендалла

\paragraph{3. Распределение не нормальное, нет оснований предполагать
монотонную зависимость.}

Переходим к номинальной шкале, применяем критерий Фишера-Пирсона

\par Случайные события $A$ и $B$ называются
\textit{независимыми}\index{Независимость событий}, если
$P(AB)=P(A)P(B)$

\par \textit{Выборочный показатель}\index{Выборочный показатель} - можем узнать
его значение только проведения опытов (соответственно точность зависит от
числа проведенных опытов)

\par \textit{Проранжировать}
(\textit{Proranzhirovat'})\index{Ранжировка} -
отсортировать количественный признак, и наименьшему элементу по признаку
поставить значение 1, наибольшему - $n$ (получится последовательность
элементов от 1 до $n$)

\end{document}
